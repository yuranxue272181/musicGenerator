import os
import torch
import numpy as np
import pretty_midi
from torch import nn

# ==== Generator å®šä¹‰ï¼ˆä¿æŒä¸å˜ï¼‰====
class Generator(nn.Module):
    def __init__(self, latent_dim, output_shape):
        super(Generator, self).__init__()
        self.latent_dim = latent_dim
        self.output_shape = output_shape
        self.fc = nn.Sequential(
            nn.Linear(latent_dim, 1024),
            nn.ReLU(),
            nn.Linear(1024, np.prod(output_shape)),
            nn.Tanh()
        )

    def forward(self, z):
        out = self.fc(z)
        out = out.view(z.size(0), *self.output_shape)
        return out


def sparsify_roll(roll, max_notes_per_frame=2, beat_step=4):
    """
    roll: shape (128, time)
    é™åˆ¶æ¯å¸§æœ€å¤šæ¿€æ´» max_notes_per_frame ä¸ª noteï¼Œ
    åªä¿ç•™ beat_step é—´éš”çš„æ—¶é—´å¸§ï¼ˆæ¨¡æ‹ŸèŠ‚æ‹ï¼‰
    """
    time_steps = roll.shape[1]
    sparse = np.zeros_like(roll)

    for t in range(0, time_steps):
        if t % beat_step != 0:
            continue  # åªä¿ç•™èŠ‚å¥ç‚¹

        top_pitches = np.argsort(roll[:, t])[-max_notes_per_frame:]
        sparse[top_pitches, t] = 1

    return sparse.astype(np.uint8)

# ==== Piano roll è½¬ MIDI ====
def piano_roll_to_midi(piano_roll, fs=100):
    """
    å¹»ç¥ç»ˆææ¸…éŸ³ç‰ˆï¼š
    - é™åˆ¶ pitch èŒƒå›´ï¼ˆé¿å…å°–å«ï¼‰
    - è°ƒæ•´ velocityï¼ˆæŸ”å’Œè¾“å‡ºï¼‰
    - ä½¿ç”¨èŠ‚å¥æ¨¡æ¿æ§åˆ¶è½ç‚¹
    - é¼“è½¨ä¿®å¤ä¸ºæ ‡å‡† GM Percussion
    """
    import pretty_midi
    midi = pretty_midi.PrettyMIDI()
    time_steps = piano_roll.shape[2]

#åƒç´ 15
    instrument_configs = [
        {"program": 80, "is_drum": False, "name": "Square Lead"},  # æ–¹æ³¢æ—‹å¾‹
        {"program": 81, "is_drum": False, "name": "Saw Lead"},  # é”¯é½¿å’Œå£°/ç‚¹ç¼€
        {"program": 38, "is_drum": False, "name": "Synth Bass"},  # ä¸‰è§’æ³¢ä½éŸ³
        {"program": 9, "is_drum": True, "name": "Noise Drums"}  # å™ªå£°é¼“ç»„
    ]
    rhythm_patterns = [
        list(range(0, time_steps, 16)),  # ğŸ¹ Piano: æ¯æ‹è½ç‚¹
        list(range(4, time_steps, 24)),  # ğŸ¸ Guitar: off-beat
        list(range(0, time_steps, 32)),  # ğŸ¸ Bass: ç¨€ç–æ ¹éŸ³
        [0, 8, 16, 24, 32, 40]           # ğŸ¥ Drum: kick/snare ç»„åˆ
    ]

    for i, roll in enumerate(piano_roll):
        cfg = instrument_configs[i % len(instrument_configs)]
        pattern = rhythm_patterns[i % len(rhythm_patterns)]

        # æ¸…ç†è¿‡é«˜éŸ³ç¬¦ï¼ˆå°–é”å£°æºï¼‰
        roll = np.clip(roll, 0, 1)
        roll[95:, :] = 0  # âœ… é™åˆ¶ pitch æœ€å¤§å€¼ï¼ˆå®‰å…¨åŒºåŸŸï¼‰

        # åªä¿ç•™èŠ‚å¥ä½ç½®çš„æœ€å¼º note
        sparse = np.zeros_like(roll)
        for t in pattern:
            top = np.argsort(roll[:, t])[-1:]
            sparse[top, t] = 1

        inst = pretty_midi.Instrument(program=cfg["program"], is_drum=cfg["is_drum"], name=cfg["name"])

        # åˆæˆ noteï¼Œç»Ÿä¸€ä½¿ç”¨è¾ƒä½åŠ›åº¦
        for pitch in range(128):
            note_on = None
            for t in range(time_steps):
                if sparse[pitch, t] == 1 and note_on is None:
                    note_on = t
                elif sparse[pitch, t] == 0 and note_on is not None:
                    inst.notes.append(pretty_midi.Note(
                        velocity=80, pitch=pitch,  # âœ… æŸ”å’ŒéŸ³é‡
                        start=note_on / fs,
                        end=t / fs
                    ))
                    note_on = None
            if note_on is not None:
                inst.notes.append(pretty_midi.Note(
                    velocity=80, pitch=pitch,
                    start=note_on / fs, end=time_steps / fs
                ))

        midi.instruments.append(inst)

    return midi








# ==== ä¸»å‡½æ•° ====

# #ç”Ÿæˆå››æ®µä¸ä¸€æ ·çš„å¹¶ç»„åˆ
# def generate_and_save_music(model_path, latent_dim=100, output_shape=(4, 128, 500), fs=100,
#                             save_path="generated_music_long.mid", num_segments=4):
#     generator = Generator(latent_dim, output_shape)
#     generator.load_state_dict(torch.load(model_path, map_location="cpu"))
#     generator.eval()
#
#     # æ‰¹é‡ç”Ÿæˆ latent å‘é‡
#     z = torch.randn(num_segments, latent_dim)
#
#     piano_rolls = []
#     with torch.no_grad():
#         generated = generator(z).numpy()  # shape: (num_segments, 4, 128, 500)
#         for i in range(num_segments):
#             piano_rolls.append(generated[i])
#
#     # æ‹¼æ¥æˆä¸€ä¸ªé•¿çš„ piano rollï¼Œæ²¿æ—¶é—´ç»´åº¦ axis=2
#     long_piano_roll = np.concatenate(piano_rolls, axis=2)  # shape: (4, 128, 500*num_segments)
#
#     midi = piano_roll_to_midi(long_piano_roll, fs=fs)
#     midi.write(save_path)
#     print(f"ğŸµ å·²ç”Ÿæˆç»„åˆå¤šæ®µçš„å¤šéŸ³è‰² MIDI æ–‡ä»¶ï¼š{save_path}")


#ç”Ÿæˆä¸€æ®µå¹¶é‡å¤å››æ¬¡
def generate_and_save_music(model_path, latent_dim=100, output_shape=(4, 128, 500), fs=100,
                            save_path="repeated_music.mid", repeat_times=4):
    generator = Generator(latent_dim, output_shape)
    generator.load_state_dict(torch.load(model_path, map_location="cpu"))
    generator.eval()

    # åªç”Ÿæˆä¸€ä¸ª latent å‘é‡
    z = torch.randn(1, latent_dim)

    with torch.no_grad():
        piano_roll = generator(z)[0].numpy()  # shape: (4, 128, 500)

    # æ²¿æ—¶é—´è½´é‡å¤æ‹¼æ¥ï¼ˆaxis=2 æ˜¯æ—¶é—´ç»´åº¦ï¼‰
    repeated_roll = np.tile(piano_roll, (1, 1, repeat_times))  # shape: (4, 128, 500 * repeat_times)

    midi = piano_roll_to_midi(repeated_roll, fs=fs)
    midi.write(save_path)
    print(f"ğŸµ å·²ç”Ÿæˆé‡å¤ {repeat_times} æ¬¡çš„å¤šéŸ³è‰² MIDI æ–‡ä»¶ï¼š{save_path}")



if __name__ == "__main__":
    base_dir = os.path.dirname(__file__)
    model_path = os.path.join(base_dir, "fixed_midi", "models", "generator_version2.pth")
    generate_and_save_music(model_path)
