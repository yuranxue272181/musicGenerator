import os
import glob
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pretty_midi

def save_pianoroll_as_midi(piano_roll, filename, fs=100):
    midi = pretty_midi.PrettyMIDI()
    for i, roll in enumerate(piano_roll):
        instrument = pretty_midi.Instrument(program=0)
        for pitch in range(128):
            active = False
            start = 0
            for t in range(roll.shape[1]):
                if roll[pitch, t] > 0 and not active:
                    active = True
                    start = t
                elif roll[pitch, t] == 0 and active:
                    end = t
                    note = pretty_midi.Note(velocity=100, pitch=pitch, start=start/fs, end=end/fs)
                    instrument.notes.append(note)
                    active = False
            if active:
                note = pretty_midi.Note(velocity=100, pitch=pitch, start=start/fs, end=roll.shape[1]/fs)
                instrument.notes.append(note)
        midi.instruments.append(instrument)
    midi.write(filename)

# -----------------------------
# æ•°æ®é¢„å¤„ç†éƒ¨åˆ†ï¼ˆå¤šè½¨ piano roll è¡¨ç¤ºï¼‰
# -----------------------------

def find_all_midi_files(root_dir):
    """
    é€’å½’éå† root_dir åŠå…¶æ‰€æœ‰å­ç›®å½•ï¼Œè¿”å›æ‰€æœ‰æ‰©å±•åä¸º .mid æˆ– .midi çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
    """
    midi_files = []
    for dirpath, dirnames, filenames in os.walk(root_dir):
        for filename in filenames:
            if filename.lower().endswith(('.mid', '.midi')):
                midi_files.append(os.path.join(dirpath, filename))
    return midi_files

# è®¾ç½® MIDI æ•°æ®ç›®å½•ä¸º db/clean_midiï¼ˆåŒ…å«å­æ–‡ä»¶å¤¹ï¼‰
base_dir = os.path.dirname(__file__)
midi_dir = os.path.join(base_dir,"fixed_midi")
print("MIDI æ•°æ®ç›®å½•ï¼š", midi_dir)

all_midi_files = find_all_midi_files(midi_dir)
print("æ‰¾åˆ°çš„ MIDI æ–‡ä»¶æ•°ï¼š", len(all_midi_files))
for f in all_midi_files:
    print(f)


def midi_to_multi_piano_roll(midi_file, fs=100, max_tracks=4, fixed_length=500):
    """
    å°† MIDI æ–‡ä»¶è½¬æ¢ä¸ºå¤šè½¨ piano roll è¡¨ç¤ºï¼Œè¿”å› shape (max_tracks, 128, fixed_length)
    ä»…æå–å‰ max_tracks ä¸ªè½¨é“ï¼Œè‹¥è½¨é“ä¸è¶³åˆ™è¡¥é›¶
    """
    try:
        midi_data = pretty_midi.PrettyMIDI(midi_file)
        tracks = []
        for instrument in midi_data.instruments:
            # å¦‚æœä¹å™¨ä¸ºç©ºï¼ˆsilentï¼‰æˆ–å±äº percussionï¼Œå¯æ ¹æ®éœ€è¦ç­›é€‰ï¼Œæ­¤å¤„ç›´æ¥å¤„ç†
            roll = instrument.get_piano_roll(fs=fs)
            roll = roll / 127.0
            tracks.append(roll)
            if len(tracks) >= max_tracks:
                break
        # å¦‚æœè½¨é“ä¸è¶³ï¼Œåˆ™è¡¥å……å…¨é›¶çŸ©é˜µ
        if len(tracks) < max_tracks:
            max_time = max((r.shape[1] for r in tracks), default=0)
            for _ in range(max_tracks - len(tracks)):
                tracks.append(np.zeros((128, max_time)))
        # å–æ‰€æœ‰è½¨é“ä¸­æœ€å¤§çš„æ—¶é—´æ­¥æ•°æˆ–å›ºå®šé•¿åº¦
        target_length = fixed_length
        processed = []
        for roll in tracks:
            if roll.shape[1] < target_length:
                pad_width = target_length - roll.shape[1]
                roll = np.pad(roll, ((0, 0), (0, pad_width)), mode='constant')
            else:
                roll = roll[:, :target_length]
            processed.append(roll)
        multi_roll = np.stack(processed, axis=0)  # shape: (max_tracks, 128, target_length)
        return multi_roll
    except Exception as e:
        print(f"Error processing {midi_file}: {e}")
        return None


class MidiDatasetMulti(Dataset):
    def __init__(self, midi_dir, fs=100, fixed_length=500, max_tracks=4):
        self.midi_files = find_all_midi_files(midi_dir)
        self.fs = fs
        self.fixed_length = fixed_length
        self.max_tracks = max_tracks
        self.data = []
        self._prepare_dataset()

    def _prepare_dataset(self):
        for midi_file in self.midi_files:
            multi_roll = midi_to_multi_piano_roll(midi_file, fs=self.fs,
                                                  max_tracks=self.max_tracks,
                                                  fixed_length=self.fixed_length)
            if multi_roll is None:
                continue
            self.data.append(multi_roll)
        if len(self.data) > 0:
            self.data = np.array(self.data)
        else:
            print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ MIDI æ•°æ®ï¼")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        sample = self.data[idx]  # shape: (max_tracks, 128, fixed_length)
        return torch.tensor(sample, dtype=torch.float32)


# -----------------------------
# GAN æ¨¡å‹ï¼ˆç”Ÿæˆå¤šè½¨ piano rollï¼‰
# -----------------------------
class Generator(nn.Module):
    def __init__(self, latent_dim, output_shape):
        """
        output_shape: (channels, 128, fixed_length)
        """
        super(Generator, self).__init__()
        self.latent_dim = latent_dim
        self.output_shape = output_shape
        self.fc = nn.Sequential(
            nn.Linear(latent_dim, 1024),
            nn.ReLU(),
            nn.Linear(1024, np.prod(output_shape)),
            nn.Tanh()
        )

    def forward(self, z):
        out = self.fc(z)
        out = out.view(z.size(0), *self.output_shape)
        return out


class Discriminator(nn.Module):
    def __init__(self, input_shape):
        super(Discriminator, self).__init__()
        self.input_shape = input_shape
        self.model = nn.Sequential(
            nn.Linear(np.prod(input_shape), 1024),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),  # æ·»åŠ  Dropout é˜²æ­¢ D è¿‡æ‹Ÿåˆ
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(512, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = x.view(x.size(0), -1)
        validity = self.model(x)
        return validity


# -----------------------------
# è®­ç»ƒå‡½æ•°
# -----------------------------
def train_musegan(midi_dir, epochs=100, batch_size=16, latent_dim=100, fs=100, fixed_length=500, max_tracks=4
     #è°ƒç”¨å·²æœ‰model
                  ,
    resume=True,
    generator_path="path/to/generator.pth",
    discriminator_path="path/to/discriminator.pth"):
    dataset = MidiDatasetMulti(midi_dir, fs=fs, fixed_length=fixed_length, max_tracks=max_tracks)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    if len(dataset) == 0:
        print("æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ MIDI æ•°æ®è·¯å¾„ã€‚")
        return

    sample_shape = dataset.data[0].shape
    print("æ ·æœ¬æ•°æ®å½¢çŠ¶:", sample_shape)

    generator = Generator(latent_dim, sample_shape)
    discriminator = Discriminator(sample_shape)

    # å¦‚æœå¯ç”¨ç»­è®­ï¼ˆresumeï¼‰ï¼Œåˆ™åŠ è½½å·²æœ‰æ¨¡å‹å‚æ•°
    if resume:
        if generator_path and os.path.exists(generator_path):
            generator.load_state_dict(torch.load(generator_path))
            print(f"âœ… Loaded Generator from: {generator_path}")
        else:
            print("âš ï¸ Generator checkpoint not found at", generator_path)

        if discriminator_path and os.path.exists(discriminator_path):
            discriminator.load_state_dict(torch.load(discriminator_path))
            print(f"âœ… Loaded Discriminator from: {discriminator_path}")
        else:
            print("âš ï¸ Discriminator checkpoint not found at", discriminator_path)

    adversarial_loss = nn.BCELoss()
    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

    for epoch in range(epochs):
        for i, real_data in enumerate(dataloader):
            current_bs = real_data.size(0)

            # ä½¿ç”¨ label smoothing
            valid = torch.ones(current_bs, 1) * 0.9
            fake = torch.zeros(current_bs, 1)

            # ---------------------
            #  è®­ç»ƒåˆ¤åˆ«å™¨ Discriminator
            # ---------------------
            optimizer_D.zero_grad()
            validity_real = discriminator(real_data)
            d_loss_real = adversarial_loss(validity_real, valid)

            z = torch.randn(current_bs, latent_dim)
            gen_data = generator(z).detach() + 0.05 * torch.randn_like(generator(z))  # ç”Ÿæˆå™¨è¾“å‡ºåŠ å™ªå£°
            validity_fake = discriminator(gen_data)
            d_loss_fake = adversarial_loss(validity_fake, fake)

            d_loss = (d_loss_real + d_loss_fake) / 2
            d_loss.backward()
            optimizer_D.step()

            # ---------------------
            #  å¤šæ¬¡è®­ç»ƒ Generator
            # ---------------------
            for _ in range(2):
                optimizer_G.zero_grad()
                z = torch.randn(current_bs, latent_dim)
                gen_data = generator(z)
                validity_fake = discriminator(gen_data)
                g_loss = adversarial_loss(validity_fake, valid)
                g_loss.backward()
                optimizer_G.step()

            if i % 10 == 0:
                print(
                    f"[Epoch {epoch + 1}/{epochs}] [Batch {i}/{len(dataloader)}] D: {d_loss.item():.4f}  G: {g_loss.item():.4f}")

        # <<< Add here
        # if (epoch + 1) % 10 == 0:
        with torch.no_grad():
            z_sample = torch.randn(1, latent_dim)
            gen_sample = generator(z_sample).squeeze(0).cpu().numpy()
            binarized = (gen_sample > 0.3).astype(np.uint8)
            output_dir = os.path.join(os.path.dirname(__file__), "generated_midis")
            os.makedirs(output_dir, exist_ok=True)
            save_path = os.path.join(output_dir, f"epoch{epoch + 1}.mid")
            save_pianoroll_as_midi(binarized, save_path)
            print(f"ğŸµ Saved generated MIDI at epoch {epoch + 1} -> {save_path}")

    models_dir = os.path.join(midi_dir, "models")
    os.makedirs(models_dir, exist_ok=True)
    torch.save(generator.state_dict(), os.path.join(models_dir, "generator_version2_2.pth"))
    torch.save(discriminator.state_dict(), os.path.join(models_dir, "discriminator_version2_2.pth"))
    print("æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå·²ä¿å­˜ã€‚")



# -----------------------------
# ä¸»å‡½æ•°å…¥å£
# -----------------------------
# #åˆ›å»ºæ–°model
# if __name__ == "__main__":
#     # å‡è®¾ MIDI æ•°æ®å­˜æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ db ç›®å½•ä¸­
#     base_dir = os.path.dirname(__file__)
#     midi_dir = os.path.join(base_dir,"fixed_midi")
#     # è°ƒç”¨è®­ç»ƒå‡½æ•°
#     #train_musegan(midi_dir, epochs=50, batch_size=16, latent_dim=100, fs=100, fixed_length=500, max_tracks=4)


#è°ƒç”¨å·²æœ‰model
if __name__ == "__main__":
    base_dir = os.path.dirname(__file__)
    midi_dir = os.path.join(base_dir, "fixed_midi")
    model_dir = os.path.join(midi_dir, "models")

    generator_ckpt = os.path.join(model_dir, "generator_version2.pth")
    discriminator_ckpt = os.path.join(model_dir, "discriminator_version2.pth")

    train_musegan(
        midi_dir=midi_dir,
        epochs=20,  # å†è®­ç»ƒ 20 è½®
        batch_size=16,
        latent_dim=100,
        fs=100,
        fixed_length=500,
        max_tracks=4,
        resume=True,  # âœ… è¿™é‡Œå¿…é¡»æ˜¾å¼è®¾ç½®
        generator_path=generator_ckpt,
        discriminator_path=discriminator_ckpt
    )
