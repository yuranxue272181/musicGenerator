import os
import torch
import numpy as np
import pretty_midi
from torch import nn

# ==== Generator å®šä¹‰ï¼ˆä¿æŒä¸å˜ï¼‰====
class Generator(nn.Module):
    def __init__(self, latent_dim, output_shape):
        super(Generator, self).__init__()
        self.latent_dim = latent_dim
        self.output_shape = output_shape
        self.fc = nn.Sequential(
            nn.Linear(latent_dim, 1024),
            nn.ReLU(),
            nn.Linear(1024, np.prod(output_shape)),
            nn.Tanh()
        )

    def forward(self, z):
        out = self.fc(z)
        out = out.view(z.size(0), *self.output_shape)
        return out


def sparsify_roll(roll, max_notes_per_frame=2, beat_step=4):
    """
    roll: shape (128, time)
    é™åˆ¶æ¯å¸§æœ€å¤šæ¿€æ´» max_notes_per_frame ä¸ª noteï¼Œ
    åªä¿ç•™ beat_step é—´éš”çš„æ—¶é—´å¸§ï¼ˆæ¨¡æ‹ŸèŠ‚æ‹ï¼‰
    """
    time_steps = roll.shape[1]
    sparse = np.zeros_like(roll)

    for t in range(0, time_steps):
        if t % beat_step != 0:
            continue  # åªä¿ç•™èŠ‚å¥ç‚¹

        top_pitches = np.argsort(roll[:, t])[-max_notes_per_frame:]
        sparse[top_pitches, t] = 1

    return sparse.astype(np.uint8)

# ==== Piano roll è½¬ MIDI ====
def piano_roll_to_midi(piano_roll, fs=100):
    """
    piano_roll: shape (tracks, 128, time)
    è¿”å›èŠ‚å¥ç¨€ç–ä¼˜åŒ–çš„ pretty_midi å¯¹è±¡
    """
    midi = pretty_midi.PrettyMIDI()
    time_steps = piano_roll.shape[2]

    # ä¹å™¨é…ç½®ï¼ˆæ›´çœŸå®ï¼‰
    instrument_configs = [
        {"program": 0,   "is_drum": False, "name": "Piano",  "beat": 8,  "notes": 3, "shift": 0},  # æ¯æ‹ 1 å’Œ 3 æ’å‡»ï¼Œæ¨¡æ‹Ÿå’Œå¼¦
        {"program": 24,  "is_drum": False, "name": "Guitar", "beat": 12, "notes": 2, "shift": 2},  # æ¨¡æ‹Ÿå‰ä»–å¼ºæ‹è½ç‚¹
        {"program": 33,  "is_drum": False, "name": "Bass",   "beat": 16, "notes": 1, "shift": 4},  # æ¯å°èŠ‚æ ¹éŸ³èŠ‚å¥ç‚¹ï¼ˆbeat 1, 3ï¼‰
        {"program": 0,   "is_drum": True,  "name": "Drums",  "beat": 4,  "notes": 3, "shift": 1},  # æ¨¡æ‹Ÿ kick/snare åœ¨èŠ‚æ‹ä¸Š
    ]

    for i, roll in enumerate(piano_roll):
        cfg = instrument_configs[i % len(instrument_configs)]
        inst = pretty_midi.Instrument(program=cfg["program"], is_drum=cfg["is_drum"], name=cfg["name"])
        roll = np.clip(roll, 0, 1)

        sparse = np.zeros_like(roll)

        # æ§åˆ¶èŠ‚å¥ç‚¹ä½
        for t in range(cfg["shift"], time_steps, cfg["beat"]):
            top = np.argsort(roll[:, t])[-cfg["notes"]:]
            sparse[top, t] = 1
        roll = sparse.astype(np.uint8)

        # è½¬æ¢ä¸º MIDI notes
        for pitch in range(roll.shape[0]):
            note_on = None
            for t in range(roll.shape[1]):
                if roll[pitch, t] == 1 and note_on is None:
                    note_on = t
                elif roll[pitch, t] == 0 and note_on is not None:
                    inst.notes.append(pretty_midi.Note(velocity=100, pitch=pitch,
                                                       start=note_on/fs, end=t/fs))
                    note_on = None
            if note_on is not None:
                inst.notes.append(pretty_midi.Note(velocity=100, pitch=pitch,
                                                   start=note_on/fs, end=time_steps/fs))

        midi.instruments.append(inst)

    return midi





# ==== ä¸»å‡½æ•° ====
def generate_and_save_music(model_path, latent_dim=100, output_shape=(4, 128, 500), fs=100, save_path="generated_music.mid"):
    generator = Generator(latent_dim, output_shape)
    generator.load_state_dict(torch.load(model_path, map_location="cpu"))
    generator.eval()

    z = torch.randn(1, latent_dim)
    with torch.no_grad():
        piano_roll = generator(z)[0].numpy()

    midi = piano_roll_to_midi(piano_roll, fs=fs)
    midi.write(save_path)
    print(f"ğŸµ å·²ç”Ÿæˆå¤šéŸ³è‰² MIDI æ–‡ä»¶ï¼š{save_path}")


if __name__ == "__main__":
    base_dir = os.path.dirname(__file__)
    model_path = os.path.join(base_dir, "fixed_midi", "models", "generator_version2.pth")
    generate_and_save_music(model_path)
